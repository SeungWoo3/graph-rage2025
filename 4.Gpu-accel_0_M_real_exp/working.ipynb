{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b6aef4f0",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1dd3b105",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기본 세팅\n",
    "import pandas as pd \n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math\n",
    "from scipy.stats import gaussian_kde\n",
    "from matplotlib import colors as mpl_colors\n",
    "import os\n",
    "import argparse\n",
    "from datetime import datetime\n",
    "from glob import glob\n",
    "from itertools import product, groupby\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "945bb1dc",
   "metadata": {},
   "source": [
    "# Font & Color"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fca7c72",
   "metadata": {},
   "source": [
    "##### TODO\n",
    "- font download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "152ebcde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# font = {'family': 'Tahoma'}\n",
    "# font = {'family': 'Times New Roman'}\n",
    "\n",
    "# plt.rc('font', **font)\n",
    "\n",
    "colors = ['blue', 'orange', 'green', 'red', 'purple', 'brown']\n",
    "colors_fill = [None, \"#54637C\", \"#587C86\", \"#5D928B\",\"#65A68D\", \n",
    "               \"#71B88E\", \"#83C98F\", \"#9CD790\", \"#BBE394\", \n",
    "               \"#D9ED9D\", \"#F1F4B0\", \"#FEFAD3\"]\n",
    "grid_color = 'gainsboro'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3e152b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def layerNum(model:str) -> int:\n",
    "    if model == \"densenet201\" :\n",
    "        return 306\n",
    "    elif model == \"resnet152\" :\n",
    "        return 206\n",
    "    elif model == \"enetb0\" :\n",
    "        return 136\n",
    "    elif model == \"csmobilenet-v2\" :\n",
    "        return 81\n",
    "    elif model == \"squeezenet\" :\n",
    "        return 50\n",
    "    elif model == \"yolov7\" :\n",
    "        return 143\n",
    "    elif model == \"yolov7-tiny\" :\n",
    "        return 99\n",
    "    elif model == \"yolov4\" :\n",
    "        return 162\n",
    "    elif model == \"yolov4-tiny\" :\n",
    "        return 38\n",
    "    elif model == \"resnet10\" :\n",
    "        return 17\n",
    "    elif model == \"yolov2-tiny\" :\n",
    "        return 16\n",
    "    else :\n",
    "        print(\"Unknown model: \", model)\n",
    "        return 0\n",
    "\n",
    "def maxCore(device:str) -> int:\n",
    "    if device == \"nano\":\n",
    "        return 4\n",
    "    if device == \"orin\":\n",
    "        return 10\n",
    "    else:\n",
    "        print(\"Unknown device: \", device)\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27c8c301",
   "metadata": {},
   "source": [
    "### Options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7f0e0c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_formats = ['png', 'pdf', 'svg']\n",
    "devices = ['nano', 'orin']\n",
    "types = [\"toy_simul\", \"real_simul\", \"real_exp\"]\n",
    "models = ['densenet201', 'resnet152', 'enetb0', 'csmobilenet-v2', 'squeezenet', 'yolov7', 'yolov7-tiny', 'yolov4', 'yolov4-tiny', 'resnet10', 'yolov2-tiny']\n",
    "\n",
    "device = 'nano'\n",
    "type = \"real_exp\"\n",
    "model = \"densenet201\"\n",
    "date_label = \"0106\"\n",
    "\n",
    "max_cores = maxCore(device)\n",
    "if type not in types:\n",
    "    print(\"Unknown type: \", type)\n",
    "layer_num = layerNum(model)\n",
    "if not os.path.exists(f\"../../csv/{date_label}\"):\n",
    "    print(f\"Invalid date: {date_label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c8eeac",
   "metadata": {},
   "outputs": [],
   "source": [
    "for save_format in save_formats:\n",
    "    directory_path = f'./{save_format}'\n",
    "    if not os.path.exists(directory_path):\n",
    "        os.makedirs(directory_path)\n",
    "        print(f\"디렉터리 '{directory_path}' 생성 완료!\")\n",
    "    else:\n",
    "        print(f\"디렉터리 '{directory_path}'가 이미 존재합니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dfe0b2a",
   "metadata": {},
   "source": [
    "### Load csv & Dataframe 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1861bb94",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = f\"../../csv/{date_label}/gpu_accel_0_M/{model}/\"\n",
    "\n",
    "# 데이터를 수집할 데이터프레임을 초기화\n",
    "columns = ['glayer', 'throughput', 'frame_rate', 'execution_time', 'cycle_time', \n",
    "           'num_thread_data', 'num_thread', 'accel_gain', 'block_loss', 'max_delay', 'min_delay']\n",
    "data_list = []\n",
    "\n",
    "num_thread = max_cores\n",
    "path = os.path.join(base_path, f\"{num_thread}thread\")\n",
    "for filename in sorted(os.listdir(path)):\n",
    "    if filename.endswith(\".csv\"):\n",
    "            num_glayer = int(filename.split('_')[2].replace('.csv', ''))\n",
    "            df = pd.read_csv(os.path.join(path, filename))\n",
    "            task_num = len(df)\n",
    "            start_preprocess_time = df[\"start_preprocess\"].iloc[0]\n",
    "            end_infer_time = df[\"end_postprocess\"].iloc[-1]\n",
    "            Throughput = task_num / (end_infer_time - start_preprocess_time) * 1000\n",
    "            if(num_glayer == 0):\n",
    "                infer_time_standard = df[\"e_infer\"].mean() - df[\"waiting_gpu\"].mean()\n",
    "            acceleration_gain = infer_time_standard - (df[\"e_infer\"].mean() - df[\"waiting_gpu\"].mean())\n",
    "\n",
    "            block_loss = df[\"waiting_gpu\"].mean()\n",
    "            max_delay = df[\"execution_time\"].max()\n",
    "            min_delay = df[\"execution_time\"].min()\n",
    "            avg_frame_rate = df[\"frame_rate\"].mean()\n",
    "            avg_execution_time = df[\"execution_time\"].mean()\n",
    "            avg_cycle_time = df[\"cycle_time\"].mean()\n",
    "            avg_num_thread_data = df[\"num_thread\"].mean()\n",
    "            \n",
    "            # 데이터프레임에 데이터 추가\n",
    "            data_list.append([num_glayer, Throughput, avg_frame_rate, avg_execution_time, \n",
    "                              avg_cycle_time, avg_num_thread_data, num_thread, acceleration_gain, \n",
    "                              block_loss, max_delay, min_delay])\n",
    "# 데이터프레임 생성\n",
    "data_df = pd.DataFrame(data_list, columns=columns)\n",
    "data_df = data_df.pivot(index='glayer', columns='num_thread')\n",
    "\n",
    "frame_rate_df = data_df['frame_rate']\n",
    "execution_time_df = data_df['execution_time']\n",
    "cycle_time_df = data_df['cycle_time']\n",
    "\n",
    "# 파일 경로 설정\n",
    "# frame_rate_file_path = './gpu-accel-GC_frame_rate_data.csv'\n",
    "# execution_time_file_path = './gpu-accel-GC_execution_time_data.csv'\n",
    "# cycle_time_file_path = './gpu-accel-GC_cycle_time_data.csv'\n",
    "\n",
    "# # 파일 저장\n",
    "# frame_rate_df.to_csv(frame_rate_file_path)\n",
    "# execution_time_df.to_csv(execution_time_file_path)\n",
    "# cycle_time_df.to_csv(cycle_time_file_path)\n",
    "\n",
    "# print(frame_rate_file_path, execution_time_file_path, cycle_time_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edfa10b7",
   "metadata": {},
   "source": [
    "### Max throughput 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "adcb5a87",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# # 결과를 저장할 리스트 초기화\n",
    "# max_values = []\n",
    "\n",
    "# # 각 스레드 수에 대해 반복\n",
    "# for num_thread in range(1, num_total_cores):\n",
    "#     if num_thread in data_df['frame_rate'].columns:\n",
    "#         # frame_rate의 최대값 찾기\n",
    "#         max_throughput = data_df['throughput'][num_thread].max()\n",
    "#         # 최대 frame_rate의 인덱스 찾기\n",
    "#         max_index = data_df['throughput'][num_thread].idxmax()\n",
    "#         # 해당 인덱스의 execution_time 가져오기\n",
    "#         corresponding_execution_time = data_df['execution_time'][num_thread].loc[max_index]\n",
    "\n",
    "#         # 결과 저장\n",
    "#         max_values.append({\n",
    "#             'num_thread': num_thread,\n",
    "#             'glayer': max_index,\n",
    "#             'max_throughput': max_throughput,\n",
    "#             'execution_time_at_max_fr': corresponding_execution_time\n",
    "#         })\n",
    "\n",
    "# # 결과 출력\n",
    "# print(\"Point for Max Frame rate\")\n",
    "# for result in max_values:\n",
    "#     print(f\"Threads: {result['num_thread']}, Glayers: {result['glayer']}, \n",
    "#           Max Throughput: {result['max_throughput']:.2f}, \n",
    "#           Execution Time: {result['execution_time_at_max_fr']:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "095ac943",
   "metadata": {},
   "source": [
    "### 다음 thread의 throughput 넘는 지점 찾기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8760b498",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 결과를 저장할 리스트 초기화\n",
    "# cross_points = []\n",
    "\n",
    "# # 각 스레드 수와 그 다음 스레드 수 비교\n",
    "# for num_thread in range(10, num_total_cores - 1):\n",
    "#     current_thread_frame_rates = data_df['frame_rate'][num_thread]\n",
    "#     next_thread_frame_rates = data_df['frame_rate'][num_thread + 1]\n",
    "#     current_thread_execution_time = data_df['execution_time'][num_thread]\n",
    "#     next_thread_execution_time = data_df['execution_time'][num_thread + 1]\n",
    "    \n",
    "#     # glayer를 순회하면서 현재 스레드의 frame_rate가 다음 스레드의 frame_rate를 넘는 첫 번째 지점 찾기\n",
    "#     for glayer in current_thread_frame_rates.index:\n",
    "#         if current_thread_frame_rates[glayer] >= next_thread_frame_rates[glayer]:\n",
    "#             cross_points.append({\n",
    "#                 'num_thread': num_thread,\n",
    "#                 'glayer': glayer,\n",
    "#                 'current_frame_rate': current_thread_frame_rates[glayer],\n",
    "#                 'next_frame_rate': next_thread_frame_rates[glayer],\n",
    "#                 'current_execution_time': current_thread_execution_time[glayer],\n",
    "#                 'next_execution_time': next_thread_execution_time[glayer]\n",
    "#             })\n",
    "#             break  # 첫 번째 조건 충족 지점에서 루프 종료\n",
    "\n",
    "# # 결과 출력\n",
    "# for point in cross_points:\n",
    "#     print(f\"Thread {point['num_thread']} exceeds Thread {point['num_thread']+1} \n",
    "#           at Glayer {point['glayer']}:\")\n",
    "#     print(f\"  Thread {point['num_thread']}: {point['current_frame_rate']:.2f} fps, \n",
    "#           Thread {point['num_thread']+1}: {point['next_frame_rate']:.2f} fps\")\n",
    "#     print(f\"  Thread {point['num_thread']}: {point['current_execution_time']:.2f} ms, \n",
    "#           Thread {point['num_thread']+1}: {point['next_execution_time']:.2f} ms\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c193a750",
   "metadata": {},
   "source": [
    "### throughput & delay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c38146b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the plot\n",
    "fig, (ax1, ax3, ax5) = plt.subplots(3, 1, figsize=(6, 12))\n",
    "ax2 = ax1.twinx()\n",
    "ax4 = ax3.twinx()\n",
    "colors = plt.cm.viridis(np.linspace(0, 1, 4))  # max_total_cores개의 색상을 viridis 컬러맵에서 선택\n",
    "# 각 스레드에 대한 데이터 플롯\n",
    "for num_thread in range(4, 5):\n",
    "    color = colors[num_thread % len(colors)]\n",
    "    color_fill = colors_fill[num_thread]\n",
    "    if num_thread in data_df.columns.levels[1]:\n",
    "        ax1.plot(data_df.index, data_df[('throughput', num_thread)], label=f\"{num_thread} threads\", color=\"tab:red\", zorder = num_thread)\n",
    "        ax2.plot(data_df.index, data_df[('execution_time', num_thread)], color=\"tab:blue\", zorder = num_thread)\n",
    "        ax3.plot(data_df.index, data_df[('accel_gain', num_thread)], color=\"tab:orange\", zorder = num_thread)\n",
    "        ax4.plot(data_df.index, data_df[('block_loss', num_thread)], color=\"tab:green\", zorder = num_thread)\n",
    "        ax5.plot(data_df.index, data_df[('accel_gain', num_thread)] - data_df[('block_loss', num_thread)], color=color, zorder = num_thread)\n",
    "        # ax1.axvline(x=max_values[num_thread - 1]['glayer'], color='gold', zorder = num_thread, linestyle='--', alpha=1, linewidth=4)\n",
    "        # ax3.axvline(x=max_values[num_thread - 1]['glayer'], color='gold', zorder = num_thread, linestyle='--', alpha=1, linewidth=4)\n",
    "        # ax5.axvline(x=max_values[num_thread - 1]['glayer'], color='gold', zorder = num_thread, linestyle='--', alpha=1, linewidth=4)\n",
    "\n",
    "        # if (num_thread == 1) or (num_thread == 2) or (num_thread == num_total_cores):\n",
    "        #     ax2.plot(data_df.index, data_df[('num_thread_data', num_thread)], label=f\"{num_thread} threads\", color=color, zorder = num_thread)\n",
    "        #     ax2.fill_between(data_df.index, data_df[('num_thread_data', num_thread)], color=color_fill, zorder=num_thread)\n",
    "        # else:\n",
    "        #     exceed_num = cross_points[num_thread - 3]['glayer']\n",
    "        #     ax2.plot(data_df.index[:exceed_num], data_df[('num_thread_data', num_thread)][:exceed_num], label=f\"{num_thread} threads\", color=color, zorder = num_thread)\n",
    "        #     ax2.fill_between(data_df.index[:exceed_num], data_df[('num_thread_data', num_thread)][:exceed_num], color=color_fill, zorder=num_thread)\n",
    "\n",
    "ax1.set_xlabel('Number of Accelerated Layers', size=12)\n",
    "ax3.set_xlabel('Number of Accelerated Layers', size=12)\n",
    "ax5.set_xlabel('Number of Accelerated Layers', size=12)\n",
    "\n",
    "ax1.set_ylabel(\"Throughput (Ntask / ms)\", size=12, color=\"tab:red\")\n",
    "ax2.set_ylabel(\"Delay(ms)\", size = 12, color=\"tab:blue\")\n",
    "ax3.set_ylabel(\"Acceleration Gain\", size=12, color=\"tab:orange\")\n",
    "ax4.set_ylabel(\"Block Loss\", size = 12, color=\"tab:green\")\n",
    "ax5.set_ylabel(\"Net Gain(Acceleration Gain - Block Loss)\", size = 12, color=color)\n",
    "\n",
    "ax1.set_title(f\"GPU-accel [0, M] with {model}\", size=12)\n",
    "ax3.set_title(f\"GPU-accel [0, M] with {model}\", size=12)\n",
    "ax5.set_title(f\"GPU-accel [0, M] with {model}\", size=12)\n",
    "\n",
    "ax1.tick_params(axis='both', labelsize=12)\n",
    "plt.tight_layout()\n",
    "ax1.grid(color='gray', alpha=0.2)\n",
    "ax3.grid(color='gray', alpha=0.2)\n",
    "ax5.grid(color='gray', alpha=0.2)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67b08aa2",
   "metadata": {},
   "source": [
    "3. real_exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "14226d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'nano'\n",
    "type = \"real_exp\"\n",
    "model = \"densenet201\"\n",
    "date_label = \"0106\"\n",
    "\n",
    "max_cores = maxCore(device)\n",
    "if type not in types:\n",
    "    print(\"Unknown type: \", type)\n",
    "layer_num = layerNum(model)\n",
    "if not os.path.exists(f\"../../csv/{date_label}\"):\n",
    "    print(f\"Invalid date: {date_label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "166de7b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cpu_layer_time_path = f\"../../csv/{date_label}/layer_time/{model}/cpu_raw_data_01blas.csv\"\n",
    "# gpu_layer_time_path = f\"../../csv/{date_label}/layer_time/{model}/gpu_raw_data.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "71d3ac55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 파일 경로 설정\n",
    "files = {\n",
    "    'Seq\\n(Full CPU)': f\"../../csv/{date_label}/sequential/{model}/sequential_cpu_01core.csv\",\n",
    "    'TPA\\n(Full CPU)': f\"../../csv/{date_label}/pipeline/{model}/pipeline_cpu.csv\",\n",
    "    'DPA\\n(Full CPU)': f\"../../csv/{date_label}/data_parallel/{model}/data-parallel_cpu_4thread.csv\",\n",
    "    'Seq\\n(Full GPU)': f\"../../csv/{date_label}/sequential/{model}/sequential_gpu_01core.csv\",\n",
    "    'TPA\\n(Full GPU)': f\"../../csv/{date_label}/pipeline/{model}/pipeline_gpu.csv\",\n",
    "    'DPA\\n(Full GPU)': f\"../../csv/{date_label}/data_parallel/{model}/data-parallel_gpu_4thread.csv\"\n",
    "}\n",
    "\n",
    "# 데이터 저장을 위한 딕셔너리\n",
    "throughput = {}\n",
    "average_execution_times = {}\n",
    "block_losses = {}\n",
    "accel_gains = {}\n",
    "pre_components = {}\n",
    "infer_components = {}\n",
    "post_components = {}\n",
    "block_components = {}\n",
    "\n",
    "# 파일 별로 데이터 로드 및 평균 계산\n",
    "for label, file_path in files.items():\n",
    "    data = pd.read_csv(file_path)\n",
    "    \n",
    "    # frame_rate의 평균 계산\n",
    "    task_num = len(data)\n",
    "    start_preprocess_time = data[\"start_preprocess\"].iloc[0]\n",
    "    end_infer_time = data[\"end_postprocess\"].iloc[-1]\n",
    "    Throughput = task_num / (end_infer_time - start_preprocess_time) * 1000\n",
    "    throughput[label] = Throughput\n",
    "    # execution_time의 평균 계산\n",
    "    average_execution_time = data['execution_time'].mean()\n",
    "    average_execution_times[label] = average_execution_time\n",
    "    if \"waiting gpu\" in data.columns:\n",
    "        block_loss = data[\"waiting gpu\"].mean()\n",
    "        block_losses[label] = block_loss\n",
    "    elif \"e_stall\" in data.columns:\n",
    "        block_loss = data[\"e_stall\"].mean()\n",
    "        block_losses[label] = block_loss\n",
    "    else:\n",
    "        block_losses[label] = 0\n",
    "\n",
    "    pre_component = data[\"e_preprocess\"].mean()\n",
    "    pre_components[label] = pre_component\n",
    "    infer_component = data[\"e_infer\"].mean()\n",
    "    infer_components[label] = infer_component\n",
    "    post_component = data[\"e_postprocess\"].mean()\n",
    "    post_components[label] = post_component\n",
    "    block_components[label] = block_losses[label]\n",
    "\n",
    "    if(label == \"Seq\\n(Full GPU)\"):\n",
    "        accel_gain = pre_components[\"Seq\\n(Full CPU)\"] - pre_components[label] + infer_components[\"Seq\\n(Full CPU)\"] - infer_components[label] + post_components[\"Seq\\n(Full CPU)\"] - post_components[label]\n",
    "        # accel_gain = average_execution_times[\"Seq\\n(Full CPU)\"] - average_execution_times[label]\n",
    "        accel_gains[label] = accel_gain\n",
    "    elif(label == \"TPA\\n(Full GPU)\"):\n",
    "        accel_gain = pre_components[\"TPA\\n(Full CPU)\"] - pre_components[label] + infer_components[\"TPA\\n(Full CPU)\"] - infer_components[label] + post_components[\"TPA\\n(Full CPU)\"] - post_components[label]\n",
    "        # accel_gain = average_execution_times[\"TPA\\n(Full CPU)\"] - average_execution_times[label]  \n",
    "        accel_gains[label] = accel_gain\n",
    "    elif(label == \"DPA\\n(Full GPU)\"):\n",
    "        accel_gain = pre_components[\"DPA\\n(Full CPU)\"] - pre_components[label] + infer_components[\"DPA\\n(Full CPU)\"] - infer_components[label] + post_components[\"DPA\\n(Full CPU)\"] - post_components[label]\n",
    "        # accel_gain = average_execution_times[\"DPA\\n(Full CPU)\"] - average_execution_times[label]\n",
    "        accel_gains[label] = accel_gain  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc4ad64f",
   "metadata": {},
   "source": [
    "# Graph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1b3da68",
   "metadata": {},
   "source": [
    "##### 1. Average Frame Rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2ea36de",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'./{save_format}/Throughput-{device}-{type}-{model}-{date_label}.{save_format}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "991c702b",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12, 6))\n",
    "\n",
    "# 첫 번째 그래프: Average Frame Rate\n",
    "bars1 = plt.bar(throughput.keys(), throughput.values(), color=colors[:3], alpha=0.7)\n",
    "plt.ylabel('Throughput (tasks/ms)', size = 15)\n",
    "plt.title(f'Throughput with {model}', size = 20)\n",
    "plt.grid(True, axis = 'y')\n",
    "plt.axvline(x=2.5, color='gray', linestyle='--', linewidth=3)  # x=2.5 위치에 점선 추가\n",
    "\n",
    "# 막대 위에 텍스트 추가\n",
    "for bar in bars1:\n",
    "    yval = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width()/2, yval, round(yval, 1), ha='center', va='bottom', size = 15)\n",
    "plt.tick_params(labelsize=15)\n",
    "plt.tight_layout()\n",
    "for save_format in save_formats:\n",
    "    plt.savefig(f'./{save_format}/Throughput-{device}-{type}-{model}-{date_label}.{save_format}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aa21285",
   "metadata": {},
   "source": [
    "##### 2. Average Execution Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dd14005",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12, 6))\n",
    "\n",
    "# 두 번째 그래프: Average Execution Time\n",
    "bars2 = plt.bar(average_execution_times.keys(), average_execution_times.values(), color=colors[:3], alpha=0.7)\n",
    "plt.ylabel('Delay (ms)', size = 15)\n",
    "plt.title(f'Delay with {model}', size = 20)\n",
    "plt.grid(True, axis = 'y')\n",
    "plt.axvline(x=2.5, color='gray', linestyle='--', linewidth=3)  # x=2.5 위치에 점선 추가\n",
    "\n",
    "# 막대 위에 텍스트 추가\n",
    "for bar in bars2:\n",
    "    yval = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width()/2, yval, round(yval, 1), ha='center', va='bottom', size = 15)\n",
    "plt.tick_params(labelsize=15)\n",
    "plt.tight_layout()\n",
    "for save_format in save_formats:\n",
    "    plt.savefig(f'./{save_format}/Delay-{device}-{type}-{model}-{date_label}.{save_format}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6ea8ce0",
   "metadata": {},
   "source": [
    "##### 3. Block Loss / Pipeline stall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "551e2852",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12, 6))\n",
    "\n",
    "# tp 번째 그래프: Block Loss\n",
    "bars3 = plt.bar(block_losses.keys(), block_losses.values(), color=colors[:3], alpha=0.7)\n",
    "plt.ylabel('Delay (ms)', size = 15)\n",
    "plt.title(f'Block Loss / Pipeline Stall with {model}', size = 20)\n",
    "plt.grid(True, axis = 'y')\n",
    "plt.axvline(x=2.5, color='gray', linestyle='--', linewidth=3)  # x=2.5 위치에 점선 추가\n",
    "\n",
    "# 막대 위에 텍스트 추가\n",
    "for bar in bars3:\n",
    "    yval = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width()/2, yval, round(yval, 1), ha='center', va='bottom', size = 15)\n",
    "plt.tick_params(labelsize=15)\n",
    "plt.tight_layout()\n",
    "for save_format in save_formats:\n",
    "    plt.savefig(f'./{save_format}/BlockLoss-{device}-{type}-{model}-{date_label}.{save_format}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a8a5210",
   "metadata": {},
   "source": [
    "##### 4. Acceleration Gain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3331a819",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(6, 5))\n",
    "\n",
    "# 네 번째 그래프: Acceleration Gain\n",
    "bars4 = plt.bar(accel_gains.keys(), accel_gains.values(), color=colors, alpha=0.7)\n",
    "plt.ylabel('Delay (ms)', size = 15)\n",
    "plt.title(f'Acceleration Gain with {model}', size = 20)\n",
    "plt.grid(True, axis = 'y')\n",
    "plt.tick_params(labelsize=15)\n",
    "\n",
    "# 막대 위에 텍스트 추가\n",
    "for bar in bars4:\n",
    "    yval = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width()/2, yval, round(yval, 1), ha='center', va='bottom', size = 15)\n",
    "plt.tick_params(labelsize=15)\n",
    "plt.tight_layout()\n",
    "for save_format in save_formats:\n",
    "    plt.savefig(f'./{save_format}/Acceleration_gain-{device}-{type}-{model}-{date_label}.{save_format}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f45d69e1",
   "metadata": {},
   "source": [
    "##### 5. Delay Component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66098390",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "x_labels = list(pre_components.keys())\n",
    "pre_values = np.array(list(pre_components.values()))\n",
    "infer_values = np.array(list(infer_components.values()))\n",
    "post_values = np.array(list(post_components.values()))\n",
    "block_values = np.array(list(block_components.values()))\n",
    "\n",
    "# 첫 번째 그래프: Delay Components\n",
    "bar1 = plt.bar(x_labels, pre_values, color='skyblue', label='Preprocess')\n",
    "bar2 = plt.bar(x_labels, infer_values, color='lightgreen',bottom=np.array(pre_values), label='Inference')\n",
    "bar3 = plt.bar(x_labels, post_values, bottom=np.array(pre_values) + np.array(infer_values), color='coral', label='Postprocess')\n",
    "bar4 = plt.bar(x_labels, block_values,\n",
    "               bottom=np.array(pre_values) + np.array(infer_values) + np.array(post_values),\n",
    "               color='gold', label='Block Loss')\n",
    "\n",
    "# 막대 위에 텍스트 추가\n",
    "for i in range(6):\n",
    "    total_height = (pre_values[i] + infer_values[i] +\n",
    "                    post_values[i] + block_values[i])\n",
    "    plt.text(i, total_height, f'{total_height:.1f}', ha='center', va='bottom', fontsize=14)\n",
    "\n",
    "plt.legend(fontsize=14)\n",
    "plt.ylabel('Delay (ms)', size = 15)\n",
    "plt.title(f'Delay Components with {model}', size = 20)\n",
    "plt.grid(True, axis = 'y')\n",
    "plt.axvline(x=2.5, color='gray', linestyle='--', linewidth=3)  # x=2.5 위치에 점선 추가\n",
    "plt.tick_params(labelsize=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f7c6e7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
