{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "83c424e2",
   "metadata": {},
   "source": [
    "### Set parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fb1b9a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "type = \"real_simul\"\n",
    "device = 'nano'\n",
    "model = \"densenet201\"\n",
    "date_label = \"0107\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6aef4f0",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1dd3b105",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기본 세팅\n",
    "import pandas as pd \n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math\n",
    "from scipy.stats import gaussian_kde\n",
    "from matplotlib import colors as mpl_colors\n",
    "import os\n",
    "import argparse\n",
    "from datetime import datetime\n",
    "from glob import glob\n",
    "from itertools import product, groupby\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "945bb1dc",
   "metadata": {},
   "source": [
    "# Font & Color"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fca7c72",
   "metadata": {},
   "source": [
    "##### TODO\n",
    "- font download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "152ebcde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# font = {'family': 'Tahoma'}\n",
    "# font = {'family': 'Times New Roman'}\n",
    "\n",
    "# plt.rc('font', **font)\n",
    "\n",
    "colors = ['blue', 'orange', 'green', 'red', 'purple', 'brown']\n",
    "grid_color = 'gainsboro'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3e152b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "def layerNum(model:str) -> int:\n",
    "    if model == \"densenet201\" :\n",
    "        return 306\n",
    "    elif model == \"resnet152\" :\n",
    "        return 206\n",
    "    elif model == \"enetb0\" :\n",
    "        return 136\n",
    "    elif model == \"csmobilenet-v2\" :\n",
    "        return 81\n",
    "    elif model == \"squeezenet\" :\n",
    "        return 50\n",
    "    elif model == \"yolov7\" :\n",
    "        return 143\n",
    "    elif model == \"yolov7-tiny\" :\n",
    "        return 99\n",
    "    elif model == \"yolov4\" :\n",
    "        return 162\n",
    "    elif model == \"yolov4-tiny\" :\n",
    "        return 38\n",
    "    elif model == \"resnet10\" :\n",
    "        return 17\n",
    "    elif model == \"yolov2-tiny\" :\n",
    "        return 16\n",
    "    else :\n",
    "        print(\"Unknown model: \", model)\n",
    "        return 0\n",
    "\n",
    "def maxCore(device:str) -> int:\n",
    "    if device == \"nano\":\n",
    "        return 4\n",
    "    if device == \"orin\":\n",
    "        return 10\n",
    "    else:\n",
    "        print(\"Unknown device: \", device)\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27c8c301",
   "metadata": {},
   "source": [
    "### Options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7f0e0c27",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_formats = ['png', 'pdf', 'svg']\n",
    "devices = ['nano', 'orin']\n",
    "types = [\"toy_simul\", \"real_simul\", \"real_exp\"]\n",
    "models = ['densenet201', 'resnet152', 'enetb0', 'csmobilenet-v2', 'squeezenet', \n",
    "          'yolov7', 'yolov7-tiny', 'yolov4', 'yolov4-tiny', 'resnet10', 'yolov2-tiny']\n",
    "\n",
    "max_cores = maxCore(device)\n",
    "if type not in types:\n",
    "    print(\"Unknown type: \", type)\n",
    "layer_num = layerNum(model)\n",
    "if not os.path.exists(f\"../../csv/{date_label}\"):\n",
    "    print(f\"Invalid date: {date_label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c8eeac",
   "metadata": {},
   "outputs": [],
   "source": [
    "for save_format in save_formats:\n",
    "    directory_path = f'./{save_format}'\n",
    "    if not os.path.exists(directory_path):\n",
    "        os.makedirs(directory_path)\n",
    "        print(f\"디렉터리 '{directory_path}' 생성 완료!\")\n",
    "    else:\n",
    "        print(f\"디렉터리 '{directory_path}'가 이미 존재합니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dfe0b2a",
   "metadata": {},
   "source": [
    "### Load csv & Dataframe 생성"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a07e2ca",
   "metadata": {},
   "source": [
    "##### 1. toy_simul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cf09b0ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "if type == \"toy_simul\":\n",
    "    models = [\"GPU >>> CPU\", \"GPU >> CPU\", \"GPU > CPU\", \"GPU > CPU | GPU < CPU\"]\n",
    "    # model = models[2]\n",
    "    max_cores = 10\n",
    "    # max_cores = maxCore(device)\n",
    "    if type not in types:\n",
    "        print(\"Unknown type: \", type)\n",
    "    contention_overhead_percent = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c17e7650",
   "metadata": {},
   "outputs": [],
   "source": [
    "if type == \"toy_simul\":\n",
    "    if model == \"GPU >>> CPU\":\n",
    "        # GPU >>> CPU\n",
    "        cpu_inference_list = [200,400,350,460,570,330,250,290,310,300]\n",
    "        gpu_inference_list = [1,3,2,5,7,8,1,3,4,1]\n",
    "    elif model == \"GPU >> CPU\":\n",
    "        # GPU >>> CPU\n",
    "        cpu_inference_list = [100,200,150,260,270,130,50,90,110,30]\n",
    "        gpu_inference_list = [1,3,2,5,7,8,1,3,4,1]\n",
    "    elif model == \"GPU > CPU\":\n",
    "        # GPU > CPU\n",
    "        cpu_inference_list = [10,20,15,26,27,13,5,9,11,3]\n",
    "        gpu_inference_list = [1,3,2,5,7,8,1,3,4,1]\n",
    "    elif model == \"GPU > CPU | GPU < CPU\":\n",
    "        # # GPU CPU 반반 (앞이 GPU 효율 좋음)\n",
    "        cpu_inference_list = [10,20,15,26,27,13,5,9,11,3]\n",
    "        gpu_inference_list = [1,3,2,5,7,18,14,15,18,5]\n",
    "    else: print(\"Unknown mode\")\n",
    "    layer_num = len(cpu_inference_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0afa8d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if type == \"toy_simul\":\n",
    "    e_preprocess = 0\n",
    "    e_postprocess = 0\n",
    "    e_inference_cpu = sum(cpu_inference_list)\n",
    "    e_inference_gpu = sum(gpu_inference_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a6d16d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if type == \"toy_simul\":\n",
    "    # 데이터 저장을 위한 딕셔너리\n",
    "    average_execution_times = {}\n",
    "    throughput = {}\n",
    "    block_losses = {}\n",
    "    accel_gains = {}\n",
    "    pre_components = {}\n",
    "    infer_components = {}\n",
    "    post_components = {}\n",
    "    block_components = {}\n",
    "\n",
    "    labels = ['Seq\\n(Full CPU)', 'TPA\\n(Full CPU)', 'DPA\\n(Full CPU)',\n",
    "              'Seq\\n(Full GPU)', 'TPA\\n(Full GPU)', 'DPA\\n(Full GPU)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "36a0d006",
   "metadata": {},
   "outputs": [],
   "source": [
    "if type == \"toy_simul\":\n",
    "    # Calculations for Sequential (Full CPU)\n",
    "    e_inference_cpu = sum(cpu_inference_list)\n",
    "    delay_seq_cpu = e_preprocess + e_inference_cpu + e_postprocess\n",
    "    average_execution_times[\"Seq\\n(Full CPU)\"] = delay_seq_cpu\n",
    "\n",
    "    throughput[\"Seq\\n(Full CPU)\"] = 1 / delay_seq_cpu * 1000\n",
    "\n",
    "    block_loss_seq_cpu = 0\n",
    "    block_losses[\"Seq\\n(Full CPU)\"] = block_loss_seq_cpu\n",
    "\n",
    "\n",
    "\n",
    "    # Calculations for Pipeline (Full CPU)\n",
    "    max_stage_cpu = max(e_preprocess, e_inference_cpu, e_postprocess)\n",
    "    if max_stage_cpu == e_preprocess:\n",
    "        pipeline_stall_cpu = e_preprocess - e_inference_cpu\n",
    "    elif max_stage_cpu == e_inference_cpu:\n",
    "        pipeline_stall_cpu = e_inference_cpu - e_preprocess\n",
    "    else:\n",
    "        pipeline_stall_cpu = e_postprocess - e_preprocess + e_postprocess - e_inference_cpu\n",
    "    block_losses[\"TPA\\n(Full CPU)\"] = pipeline_stall_cpu\n",
    "\n",
    "    delay_tpa_cpu = e_preprocess + e_inference_cpu + e_postprocess + pipeline_stall_cpu\n",
    "    average_execution_times[\"TPA\\n(Full CPU)\"] = delay_tpa_cpu\n",
    "\n",
    "    throughput_tpa_cpu = 1 / max_stage_cpu * 1000\n",
    "    throughput[\"TPA\\n(Full CPU)\"] = throughput_tpa_cpu\n",
    "\n",
    "\n",
    "    # Calculations for Data-parallel (Full CPU)\n",
    "    contention_overhead_cpu = (delay_seq_cpu * contention_overhead_percent) / 100\n",
    "    # block_losses[\"DPA\\n(Full CPU)\"] = contention_overhead_cpu\n",
    "\n",
    "    delay_dpa_cpu = delay_seq_cpu + contention_overhead_cpu\n",
    "    throughput_dpa_cpu = 1 / (delay_dpa_cpu / max_cores) * 1000\n",
    "    throughput[\"DPA\\n(Full CPU)\"] = throughput_dpa_cpu\n",
    "\n",
    "    block_loss_dpa_cpu = 0\n",
    "    block_losses[\"DPA\\n(Full CPU)\"] = block_loss_dpa_cpu\n",
    "\n",
    "    delay_dpa_cpu = delay_dpa_cpu + block_loss_dpa_cpu\n",
    "    average_execution_times[\"DPA\\n(Full CPU)\"] = delay_dpa_cpu\n",
    "\n",
    "\n",
    "    # Calculations for Sequential (Full GPU)\n",
    "    e_inference_gpu = sum(gpu_inference_list)\n",
    "    delay_seq_gpu = e_preprocess + e_inference_gpu + e_postprocess\n",
    "    average_execution_times[\"Seq\\n(Full GPU)\"] = delay_seq_gpu\n",
    "\n",
    "    throughput_seq_gpu = 1 / delay_seq_gpu * 1000\n",
    "    throughput[\"Seq\\n(Full GPU)\"] = throughput_seq_gpu\n",
    "\n",
    "    block_loss_seq_gpu = 0\n",
    "    block_losses[\"Seq\\n(Full GPU)\"] = block_loss_seq_gpu\n",
    "\n",
    "\n",
    "    # Calculations for Pipeline (Full GPU)\n",
    "    max_stage_gpu = max(e_preprocess, e_inference_gpu, e_postprocess)\n",
    "    if max_stage_gpu == e_preprocess:\n",
    "        pipeline_stall_gpu = e_preprocess - e_inference_gpu\n",
    "    elif max_stage_gpu == e_inference_gpu:\n",
    "        pipeline_stall_gpu = e_inference_gpu - e_preprocess\n",
    "    else:\n",
    "        pipeline_stall_gpu = e_postprocess - e_preprocess + e_postprocess - e_inference_gpu\n",
    "    block_losses[\"TPA\\n(Full GPU)\"] = pipeline_stall_gpu\n",
    "\n",
    "    delay_tpa_gpu = e_preprocess + e_inference_gpu + e_postprocess + pipeline_stall_gpu\n",
    "    average_execution_times[\"TPA\\n(Full GPU)\"] = delay_tpa_gpu\n",
    "\n",
    "    throughput_tpa_gpu = 1 / max_stage_gpu * 1000\n",
    "    throughput[\"TPA\\n(Full GPU)\"] = throughput_tpa_gpu\n",
    "\n",
    "\n",
    "    # Calculations for Data-parallel (Full GPU)\n",
    "    contention_overhead_gpu = (delay_seq_gpu * contention_overhead_percent) / 100\n",
    "\n",
    "    delay_dpa_gpu = delay_seq_gpu + contention_overhead_gpu\n",
    "    throughput_dpa_gpu = 1 / max(delay_dpa_gpu / max_cores, e_inference_gpu) * 1000\n",
    "    throughput[\"DPA\\n(Full GPU)\"] = throughput_dpa_gpu\n",
    "\n",
    "    block_loss_dpa_gpu = e_inference_gpu * (max_cores-1) - (e_preprocess+e_postprocess)\n",
    "    if block_loss_dpa_gpu < 0 : block_loss_dpa_gpu = 0\n",
    "    block_losses[\"DPA\\n(Full GPU)\"] = block_loss_dpa_gpu\n",
    "\n",
    "    delay_dpa_gpu = delay_dpa_gpu + block_loss_dpa_gpu\n",
    "    average_execution_times[\"DPA\\n(Full GPU)\"] = delay_dpa_gpu\n",
    "\n",
    "    accel_gain = e_inference_cpu - e_inference_gpu\n",
    "    accel_gains[\"Seq\\n(Full GPU)\"] = accel_gain\n",
    "    accel_gains[\"TPA\\n(Full GPU)\"] = accel_gain\n",
    "    accel_gains[\"DPA\\n(Full GPU)\"] = accel_gain\n",
    "\n",
    "    for label in labels:\n",
    "        pre_components[label] = e_preprocess\n",
    "        if label[-4:-1] == \"CPU\":\n",
    "            infer_components[label] = e_inference_cpu\n",
    "        else:\n",
    "            infer_components[label] = e_inference_gpu\n",
    "        post_components[label] = e_postprocess\n",
    "        block_components[label] = block_losses[label]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "141c0150",
   "metadata": {},
   "source": [
    "2. real_simul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bc72ebad",
   "metadata": {},
   "outputs": [],
   "source": [
    "if type == 'real_simul':\n",
    "    max_cores = maxCore(device)\n",
    "    if type not in types:\n",
    "        print(\"Unknown type: \", type)\n",
    "    layer_num = layerNum(model)\n",
    "    if not os.path.exists(f\"../../csv/{date_label}\"):\n",
    "        print(f\"Invalid date: {date_label}\")\n",
    "\n",
    "    contention_overhead_percent = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "037e861a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if type == 'real_simul':\n",
    "    cpu_file_path = f'../../csv/{date_label}/layer_time/{model}/cpu_raw_data_01blas.csv'\n",
    "    gpu_file_path = f'../../csv/{date_label}/layer_time/{model}/gpu_raw_data.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "df9c3494",
   "metadata": {},
   "outputs": [],
   "source": [
    "if type == 'real_simul':\n",
    "    cpu_data = pd.read_csv(cpu_file_path)\n",
    "\n",
    "    e_preprocess = np.mean(cpu_data[\"e_preprocess\"])\n",
    "    e_postprocess = np.mean(cpu_data[\"e_postprocess\"])\n",
    "\n",
    "    layer_columns = [col for col in cpu_data.columns if col.startswith('layer')]\n",
    "    layer_num = 0\n",
    "    layer_averages_cpu = {}\n",
    "    for col in layer_columns:\n",
    "        # 열 제목에서 숫자만 추출\n",
    "        col_number = int(re.search(r'\\d+', col).group())\n",
    "        # 해당 열의 평균 계산 및 저장\n",
    "        layer_averages_cpu[col_number] = cpu_data[col].mean()\n",
    "        if layer_num < col_number : layer_num = col_number\n",
    "\n",
    "        \n",
    "    gpu_data = pd.read_csv(gpu_file_path)\n",
    "\n",
    "    layer_columns = [col for col in gpu_data.columns if col.startswith('layer')]\n",
    "    layer_num = 0\n",
    "    layer_averages_gpu = {}\n",
    "    for col in layer_columns:\n",
    "        # 열 제목에서 숫자만 추출\n",
    "        col_number = int(re.search(r'\\d+', col).group())\n",
    "        # 해당 열의 평균 계산 및 저장\n",
    "        layer_averages_gpu[col_number] = gpu_data[col].mean()\n",
    "        if layer_num < col_number : layer_num = col_number\n",
    "\n",
    "    # CPU와 GPU 인퍼런스 리스트 생성\n",
    "    cpu_inference_list = list(layer_averages_cpu.values())\n",
    "    gpu_inference_list = list(layer_averages_gpu.values())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "009a289f",
   "metadata": {},
   "source": [
    "##### [TODO]\n",
    "##### 아래 두 블럭 무슨 기능하는지 확인하기\n",
    "###### reference code 본 결과, layer_time 정보로 simulation으로 계산하는 부분으로 보임"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2eee3c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess Layer와 Postprocess Layer 앞 뒤에 넣기\n",
    "layer_num = len(cpu_inference_list)\n",
    "print(e_preprocess, e_postprocess)\n",
    "cpu_inference_list.insert(0, e_preprocess)\n",
    "cpu_inference_list.append(e_postprocess)\n",
    "gpu_inference_list.insert(0, 0)\n",
    "gpu_inference_list.append(0)\n",
    "\n",
    "\n",
    "# acceleration_type 앞 뒤에 CPU (0) 넣기\n",
    "# [0,M] & [start, M] 구성 찾기\n",
    "all_results = []\n",
    "acceleration_type = []\n",
    "\n",
    "# 모든 start 값에 대한 배열 생성\n",
    "for start in range(0, 1):\n",
    "    result = []\n",
    "    for i in range(start, layer_num):\n",
    "        row = [0] + [0] * start + [1] * (i - start + 1) + [0] * (layer_num - (i + 1)) + [0]\n",
    "        result.append(row)\n",
    "        acceleration_type.append(row)\n",
    "    all_results.append(result)\n",
    "# print(acceleration_type)\n",
    "acceleration_type.sort(key=lambda x: (x.count(1), next((i for i, v in enumerate(x) if v == 1), layer_num+2)))\n",
    "# print(acceleration_type)\n",
    "\n",
    "layer_num = len(cpu_inference_list)\n",
    "print(len(acceleration_type))\n",
    "print(len(acceleration_type[0]))\n",
    "print(layer_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ff4650e",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_thread = max_cores\n",
    "num_repeat = 100  # 반복 횟수\n",
    "\n",
    "output_cycle_time = []\n",
    "output_frame_rate = []\n",
    "max_execution_time_list = []\n",
    "min_execution_time_list = []\n",
    "avg_execution_time_list = []\n",
    "total_execution_time_list = []\n",
    "throughput_list = []\n",
    "acceleration_gain_list = []\n",
    "block_time_list = []\n",
    "num_accelerated_layer_list = []\n",
    "\n",
    "for test_case in range(0, len(acceleration_type)):\n",
    "    # target_case 가져오기\n",
    "    target_case = acceleration_type[test_case]\n",
    "    count_of_ones = target_case.count(1)\n",
    "    num_accelerated_layer_list.append(count_of_ones)\n",
    "    # if test_case == 1: print(target_case)\n",
    "    \n",
    "    # 연속된 0과 1을 segment 단위로 묶기\n",
    "    segments = [list(g) for k, g in groupby(target_case)]\n",
    "    # if test_case == 1: print(segments)\n",
    "    \n",
    "    # 각 segment의 delay 및 타입 계산\n",
    "    segment_delays = []\n",
    "    segment_types = []\n",
    "    start_idx = 0\n",
    "    \n",
    "    for segment in segments:\n",
    "        segment_type = segment[0]  # 0 (CPU) 또는 1 (GPU)\n",
    "        segment_length = len(segment)\n",
    "        \n",
    "        # 해당 segment의 delay 계산\n",
    "        if segment_type == 0:\n",
    "            delay = sum(cpu_inference_list[start_idx:start_idx + segment_length])\n",
    "            segment_types.append(\"cpu\")\n",
    "        else:\n",
    "            delay = sum(gpu_inference_list[start_idx:start_idx + segment_length])\n",
    "            segment_types.append(\"gpu\")\n",
    "        \n",
    "        segment_delays.append(delay)\n",
    "        start_idx += segment_length  # 다음 segment의 시작 인덱스 업데이트\n",
    "    \n",
    "    # 결과 출력\n",
    "    # for i, (delay, segment_type) in enumerate(zip(segment_delays, segment_types)):\n",
    "    #     print(f\"Segment {i + 1}: Type = {segment_type}, Delay = {delay}\")\n",
    "    \n",
    "    segment_type = segment_types\n",
    "    segment_delay = segment_delays\n",
    "    \n",
    "    regular_output_list = []\n",
    "    total_delay_ = sum(segment_delay)\n",
    "    \n",
    "    for input_pattern in range(0, 1):\n",
    "        data_arrival_interval = input_pattern\n",
    "    \n",
    "        task_start_time = [i * data_arrival_interval for i in range(num_thread * num_repeat)]  # [0, 5, 10, 15, 20, 25]\n",
    "        gpu_available_time = [[[0, float('inf')]] for _ in range(num_thread)]\n",
    "        segment_end_times = task_start_time[:num_thread]  # 각 스레드의 세그먼트 end_time 초기화\n",
    "        \n",
    "        # 시각화를 위한 데이터 수집\n",
    "        execution_data = {i: [] for i in range(num_thread)}  # 각 스레드의 작업 시작과 끝 시간 저장\n",
    "        \n",
    "        for repeat in range(num_repeat):\n",
    "            # print(f\"\\nRepeat {repeat + 1} 시작:\")\n",
    "            # 각 세그먼트를 순회\n",
    "            for k in range(len(segment_type)):\n",
    "                for i in range(num_thread):\n",
    "                    # 첫 번째 세그먼트의 시작 시간 조정\n",
    "                    if k == 0:\n",
    "                        start_time = max(segment_end_times[i], task_start_time[i + num_thread * repeat])\n",
    "                    else:\n",
    "                        start_time = segment_end_times[i]\n",
    "                        \n",
    "                    end_time = start_time + segment_delay[k]\n",
    "        \n",
    "                    if segment_type[k] == 'gpu':\n",
    "                        start_time = max(start_time, gpu_available_time[i][0][0])\n",
    "                        end_time = start_time + segment_delay[k]\n",
    "        \n",
    "                        for interval in gpu_available_time[i]:\n",
    "                            gpu_use_time = end_time - start_time\n",
    "                            # print(interval[1]-interval[0])\n",
    "                            if (interval[1]-interval[0]) < gpu_use_time:\n",
    "                                pass\n",
    "                            else:\n",
    "                                start_time = max(start_time, interval[0])\n",
    "                                end_time = start_time + segment_delay[k]\n",
    "                                break\n",
    "                        \n",
    "                        # 시각화 데이터에 추가\n",
    "                        execution_data[i].append((start_time, end_time, segment_type[k]))\n",
    "        \n",
    "                        \n",
    "                        # 해당 스레드의 gpu_available_time에서 start_time 이전 값을 삭제\n",
    "                        new_available_time = []\n",
    "                        for interval in gpu_available_time[i]:\n",
    "                            if interval[1] > start_time:\n",
    "                                if interval[0] < start_time:\n",
    "                                    new_available_time.append([start_time, interval[1]])\n",
    "                                else:\n",
    "                                    new_available_time.append(interval)\n",
    "                        gpu_available_time[i] = new_available_time\n",
    "        \n",
    "                        # 모든 스레드에 대해 gpu_available_time을 업데이트\n",
    "                        for j in range(num_thread):\n",
    "                            new_available_time = []\n",
    "                            for interval in gpu_available_time[j]:\n",
    "                                if end_time <= interval[0] or start_time >= interval[1]:\n",
    "                                    new_available_time.append(interval)\n",
    "                                else:\n",
    "                                    if interval[0] < start_time:\n",
    "                                        new_available_time.append([interval[0], start_time])\n",
    "                                    if interval[1] > end_time:\n",
    "                                        new_available_time.append([end_time, interval[1]])\n",
    "                            gpu_available_time[j] = new_available_time\n",
    "        \n",
    "                    elif segment_type[k] == 'cpu':\n",
    "                        # 시각화 데이터에 추가\n",
    "                        execution_data[i].append((start_time, end_time, segment_type[k]))\n",
    "        \n",
    "                        # 현재 스레드의 gpu_available_time에서 end_time 이하의 구간을 삭제\n",
    "                        new_available_time = []\n",
    "                        for interval in gpu_available_time[i]:\n",
    "                            if interval[1] > end_time:\n",
    "                                if interval[0] < end_time:\n",
    "                                    new_available_time.append([end_time, interval[1]])\n",
    "                                else:\n",
    "                                    new_available_time.append(interval)\n",
    "                        gpu_available_time[i] = new_available_time\n",
    "        \n",
    "                    # 현재 세그먼트의 종료 시간을 기록하여 다음 세그먼트 시작 시간을 결정\n",
    "                    segment_end_times[i] = end_time\n",
    "                    # print(f\"스레드 {i + 1}의 {segment_type[k]} 세그먼트 후 gpu_available_time:\", gpu_available_time)\n",
    "        \n",
    "        # 각 스레드의 end_time 기록을 위한 초기화\n",
    "        thread_end_times = [0] * num_thread  # 각 스레드의 마지막 end_time 기록\n",
    "        \n",
    "        # Start time, end time, and end-to-end delay lists 초기화\n",
    "        release_time_list = []\n",
    "        start_time_list = []\n",
    "        end_time_list = []\n",
    "        end_to_end_delay_list = []\n",
    "        \n",
    "        # End-to-end delay 계산 및 리스트에 저장\n",
    "        for repeat in range(num_repeat):\n",
    "            for thread in range(num_thread):\n",
    "                # 각 task의 첫 번째 세그먼트의 start_time과 마지막 세그먼트의 end_time 찾기\n",
    "                task_segments = execution_data[thread][repeat * len(segment_type):(repeat + 1) * len(segment_type)]\n",
    "                start_time = task_segments[0][0]\n",
    "                end_time = task_segments[-1][1]\n",
    "                end_to_end_delay = end_time - thread_end_times[thread]\n",
    "                # print(start_time, end_time)\n",
    "                \n",
    "                # 리스트에 추가\n",
    "                release_time_list.append(thread_end_times[thread])\n",
    "                start_time_list.append(start_time)\n",
    "                end_time_list.append(end_time)\n",
    "                end_to_end_delay_list.append(end_to_end_delay)\n",
    "        \n",
    "                # 현재 스레드의 마지막 end_time 업데이트\n",
    "                thread_end_times[thread] = end_time\n",
    "                \n",
    "                # print(f\"Repeat {repeat + 1}, Thread {thread + 1} - Start: {start_time}, End: {end_time}, End-to-End Delay: {end_to_end_delay}\")\n",
    "        \n",
    "        # 리스트 출력\n",
    "        # print(\"\\nRelease Time List:\", release_time_list)\n",
    "        # print(\"Start Time List:\", start_time_list)\n",
    "        # print(\"End Time List:\", end_time_list)\n",
    "        # print(\"End-to-End Delay List:\", end_to_end_delay_list)\n",
    "        \n",
    "        # Start time gap list와 end time gap list 초기화\n",
    "        start_time_gap_list = []\n",
    "        end_time_gap_list = []\n",
    "        \n",
    "        # Start time과 end time gap 계산\n",
    "        for i in range(1, len(release_time_list)):\n",
    "            start_time_gap = release_time_list[i] - release_time_list[i - 1]\n",
    "            end_time_gap = end_time_list[i] - end_time_list[i - 1]\n",
    "            \n",
    "            start_time_gap_list.append(start_time_gap)\n",
    "            end_time_gap_list.append(end_time_gap)\n",
    "            \n",
    "        max_execution_time_list.append(np.max(end_to_end_delay_list[num_repeat:]))\n",
    "        min_execution_time_list.append(np.min(end_to_end_delay_list[num_repeat:]))\n",
    "        avg_execution_time_list.append(np.mean(end_to_end_delay_list[num_repeat:]))\n",
    "        total_execution_time = end_time_list[-1] - release_time_list[num_repeat]\n",
    "        # print(\"here\", end_time_list[-1], release_time_list[num_repeat])\n",
    "        throughput = (num_repeat * num_thread) / total_execution_time * 1000\n",
    "        total_execution_time_list.append(total_execution_time)\n",
    "        throughput_list.append(throughput)\n",
    "        # print(test_case, \"-->\", end_time_gap_list, end_to_end_delay_list)\n",
    "\n",
    "        corresponding_acceleration_type = acceleration_type[test_case]\n",
    "\n",
    "        # 합 계산\n",
    "        total_inference_time = sum(\n",
    "            cpu_inference_list[i] if corresponding_acceleration_type[i] == 0 else gpu_inference_list[i]\n",
    "            for i in range(layer_num)\n",
    "        )\n",
    "        \n",
    "        # blcok loss & acceleration gain\n",
    "        total_cpu_time = sum(cpu_inference_list)\n",
    "        acceleration_gain = total_cpu_time - total_inference_time\n",
    "        acceleration_gain_list.append(acceleration_gain)\n",
    "        max_execution_time = np.max(end_to_end_delay_list[num_repeat:])\n",
    "        block_time = max_execution_time-total_inference_time\n",
    "        block_time_list.append(block_time)\n",
    "        \n",
    "        print(test_case, \"-->\", np.max(end_to_end_delay_list[num_repeat:]), np.min(end_to_end_delay_list[num_repeat:]), np.mean(end_to_end_delay_list[num_repeat:]), \"--> total_execution_time:\", total_execution_time, \"throughput:\", throughput)\n",
    "        print(test_case, total_cpu_time, max_execution_time,total_inference_time, \"-->\", f\"가속 이득: {acceleration_gain} 블락 손실: {block_time}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67b08aa2",
   "metadata": {},
   "source": [
    "3. real_exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "14226d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if type == 'real_exp':\n",
    "    # device = 'nano'\n",
    "    # type = \"real_exp\"\n",
    "    # model = \"densenet201\"\n",
    "    # date_label = \"0106\"\n",
    "\n",
    "    max_cores = maxCore(device)\n",
    "    if type not in types:\n",
    "        print(\"Unknown type: \", type)\n",
    "    layer_num = layerNum(model)\n",
    "    if not os.path.exists(f\"../../csv/{date_label}\"):\n",
    "        print(f\"Invalid date: {date_label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "166de7b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# if type == 'real_exp':\n",
    "#     cpu_layer_time_path = f\"../../csv/{date_label}/layer_time/{model}/cpu_raw_data_01blas.csv\"\n",
    "#     gpu_layer_time_path = f\"../../csv/{date_label}/layer_time/{model}/gpu_raw_data.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "71d3ac55",
   "metadata": {},
   "outputs": [],
   "source": [
    "if type == 'real_exp':\n",
    "    # 파일 경로 설정\n",
    "    files = {\n",
    "        'Seq\\n(Full CPU)': f\"../../csv/{date_label}/sequential/{model}/sequential_cpu_01core.csv\",\n",
    "        'TPA\\n(Full CPU)': f\"../../csv/{date_label}/pipeline/{model}/pipeline_cpu.csv\",\n",
    "        'DPA\\n(Full CPU)': f\"../../csv/{date_label}/data_parallel/{model}/data-parallel_cpu_4thread.csv\",\n",
    "        'Seq\\n(Full GPU)': f\"../../csv/{date_label}/sequential/{model}/sequential_gpu_01core.csv\",\n",
    "        'TPA\\n(Full GPU)': f\"../../csv/{date_label}/pipeline/{model}/pipeline_gpu.csv\",\n",
    "        'DPA\\n(Full GPU)': f\"../../csv/{date_label}/data_parallel/{model}/data-parallel_gpu_4thread.csv\"\n",
    "    }\n",
    "\n",
    "    # 데이터 저장을 위한 딕셔너리\n",
    "    throughput = {}\n",
    "    average_execution_times = {}\n",
    "    block_losses = {}\n",
    "    accel_gains = {}\n",
    "    pre_components = {}\n",
    "    infer_components = {}\n",
    "    post_components = {}\n",
    "    block_components = {}\n",
    "\n",
    "    # 파일 별로 데이터 로드 및 평균 계산\n",
    "    for label, file_path in files.items():\n",
    "        data = pd.read_csv(file_path)\n",
    "        \n",
    "        # frame_rate의 평균 계산\n",
    "        task_num = len(data)\n",
    "        start_preprocess_time = data[\"start_preprocess\"].iloc[0]\n",
    "        end_infer_time = data[\"end_postprocess\"].iloc[-1]\n",
    "        Throughput = task_num / (end_infer_time - start_preprocess_time) * 1000\n",
    "        throughput[label] = Throughput\n",
    "        # execution_time의 평균 계산\n",
    "        average_execution_time = data['execution_time'].mean()\n",
    "        average_execution_times[label] = average_execution_time\n",
    "        if \"waiting gpu\" in data.columns:\n",
    "            block_loss = data[\"waiting gpu\"].mean()\n",
    "            block_losses[label] = block_loss\n",
    "        elif \"e_stall\" in data.columns:\n",
    "            block_loss = data[\"e_stall\"].mean()\n",
    "            block_losses[label] = block_loss\n",
    "        else:\n",
    "            block_losses[label] = 0\n",
    "\n",
    "        pre_component = data[\"e_preprocess\"].mean()\n",
    "        pre_components[label] = pre_component\n",
    "        infer_component = data[\"e_infer\"].mean()\n",
    "        infer_components[label] = infer_component\n",
    "        post_component = data[\"e_postprocess\"].mean()\n",
    "        post_components[label] = post_component\n",
    "        block_components[label] = block_losses[label]\n",
    "\n",
    "        if(label == \"Seq\\n(Full GPU)\"):\n",
    "            accel_gain = pre_components[\"Seq\\n(Full CPU)\"] - pre_components[label] + infer_components[\"Seq\\n(Full CPU)\"] - infer_components[label] + post_components[\"Seq\\n(Full CPU)\"] - post_components[label]\n",
    "            # accel_gain = average_execution_times[\"Seq\\n(Full CPU)\"] - average_execution_times[label]\n",
    "            accel_gains[label] = accel_gain\n",
    "        elif(label == \"TPA\\n(Full GPU)\"):\n",
    "            accel_gain = pre_components[\"TPA\\n(Full CPU)\"] - pre_components[label] + infer_components[\"TPA\\n(Full CPU)\"] - infer_components[label] + post_components[\"TPA\\n(Full CPU)\"] - post_components[label]\n",
    "            # accel_gain = average_execution_times[\"TPA\\n(Full CPU)\"] - average_execution_times[label]  \n",
    "            accel_gains[label] = accel_gain\n",
    "        elif(label == \"DPA\\n(Full GPU)\"):\n",
    "            accel_gain = pre_components[\"DPA\\n(Full CPU)\"] - pre_components[label] + infer_components[\"DPA\\n(Full CPU)\"] - infer_components[label] + post_components[\"DPA\\n(Full CPU)\"] - post_components[label]\n",
    "            # accel_gain = average_execution_times[\"DPA\\n(Full CPU)\"] - average_execution_times[label]\n",
    "            accel_gains[label] = accel_gain  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc4ad64f",
   "metadata": {},
   "source": [
    "# Graph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83f7c6e7",
   "metadata": {},
   "source": [
    "##### 1. throughput and delay - glayers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aebf344c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_accelerated_layer_list를 기준으로 정렬\n",
    "sorted_data = sorted(zip(num_accelerated_layer_list, max_execution_time_list, throughput_list))\n",
    "\n",
    "# 정렬된 데이터 분리\n",
    "sorted_num_accelerated_layer_list, sorted_max_execution_time_list, sorted_throughput_list = zip(*sorted_data)\n",
    "\n",
    "# MAX throughput과 그때의 delay 계산 및 출력\n",
    "max_throughput = max(sorted_throughput_list)\n",
    "max_throughput_index = sorted_throughput_list.index(max_throughput)\n",
    "corresponding_delay = sorted_max_execution_time_list[max_throughput_index]\n",
    "corresponding_delay_num_of_accelerated_layers = sorted_num_accelerated_layer_list[max_throughput_index]\n",
    "\n",
    "print(\"MAX Throughput Index:\", max_throughput_index)\n",
    "print(\"MAX Throughput:\", max_throughput)\n",
    "print(\"Corresponding Number of Accelerated Layers:\", corresponding_delay_num_of_accelerated_layers)\n",
    "print(\"Corresponding Delay:\", corresponding_delay)\n",
    "\n",
    "\n",
    "# 2개의 y축을 가지는 그래프 생성\n",
    "fig, ax1 = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "# 첫 번째 y축 (total_execution_time_list)\n",
    "color = \"tab:red\"\n",
    "ax1.set_ylabel(\"Throughput (task/ms)\", color=color, size=20)\n",
    "ax1.set_xlabel(\"Number of Accelerated Layers\", size=20)\n",
    "\n",
    "ax1.plot(sorted_num_accelerated_layer_list, sorted_throughput_list, color=color, linestyle=\"-\", label=\"Throughput\")\n",
    "ax1.tick_params(axis=\"y\", labelcolor=color, labelsize=12)\n",
    "ax1.legend(loc=\"upper left\")\n",
    "\n",
    "# 두 번째 y축 (throughput_list)\n",
    "ax2 = ax1.twinx()\n",
    "color = \"tab:blue\"\n",
    "ax2.set_xlabel(\"Layer index\", size=20)\n",
    "ax2.set_ylabel(\"Delay (ms)\", color=color, size=20)\n",
    "ax2.plot(sorted_num_accelerated_layer_list, sorted_max_execution_time_list, color=color, linestyle=\"-\", label=\"Delay\")\n",
    "ax2.tick_params(axis=\"y\", labelcolor=color, labelsize=12)\n",
    "ax2.legend(loc=\"upper right\")\n",
    "\n",
    "ax1.grid(True, which=\"both\", linestyle=\"--\", linewidth=0.5, alpha=0.7)\n",
    "\n",
    "ax1.axvline(x=corresponding_delay_num_of_accelerated_layers, color=\"gold\", linewidth=3, linestyle=\"--\")\n",
    "ax1.text(corresponding_delay_num_of_accelerated_layers, np.max(sorted_throughput_list) / 2, \"Max Throughput\", color=\"black\", rotation=90, \n",
    "         verticalalignment=\"center\", horizontalalignment=\"right\", fontsize=14)\n",
    "\n",
    "plt.title(f\"GPU-accel [0,M] with {model}\", size=20)\n",
    "plt.tight_layout()\n",
    "for save_format in save_formats:\n",
    "    plt.savefig(f'./{save_format}/Throughput_Delay-GLayer-{device}-{type}-{model}-{date_label}.{save_format}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7af01c8",
   "metadata": {},
   "source": [
    "##### 2. acceleration gain and block loss - glayers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff46a69c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_accelerated_layer_list를 기준으로 정렬\n",
    "sorted_data = sorted(zip(num_accelerated_layer_list, acceleration_gain_list, block_time_list))\n",
    "\n",
    "# 정렬된 데이터 분리\n",
    "sorted_num_accelerated_layer_list, sorted_acceleration_gain_list, sorted_block_time_list = zip(*sorted_data)\n",
    "\n",
    "# 2개의 y축을 가지는 그래프 생성\n",
    "fig, ax1 = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "# 첫 번째 y축 (total_execution_time_list)\n",
    "color = \"tab:orange\"\n",
    "ax1.set_ylabel(\"Acceleration Gain\", color=color, size=20)\n",
    "ax1.set_xlabel(\"Number of Accelerated Layers\", size=20)\n",
    "\n",
    "ax1.plot(sorted_num_accelerated_layer_list, sorted_acceleration_gain_list, color=color, linestyle=\"-\", label=\"Throughput\")\n",
    "ax1.tick_params(axis=\"y\", labelcolor=color, labelsize=12)\n",
    "ax1.legend(loc=\"upper left\")\n",
    "\n",
    "# 두 번째 y축 (throughput_list)\n",
    "ax2 = ax1.twinx()\n",
    "color = \"tab:green\"\n",
    "ax2.set_xlabel(\"Layer index\", size=20)\n",
    "ax2.set_ylabel(\"Block Loss\", color=color, size=20)\n",
    "ax2.plot(sorted_num_accelerated_layer_list, sorted_block_time_list, color=color, linestyle=\"-\", label=\"Delay\")\n",
    "ax2.tick_params(axis=\"y\", labelcolor=color, labelsize=12)\n",
    "ax2.legend(loc=\"upper right\")\n",
    "\n",
    "ax1.grid(True, which=\"both\", linestyle=\"--\", linewidth=0.5, alpha=0.7)\n",
    "ax1.axvline(x=corresponding_delay_num_of_accelerated_layers, color=\"gold\", linewidth=3, linestyle=\"--\")\n",
    "ax1.text(corresponding_delay_num_of_accelerated_layers, np.max(sorted_acceleration_gain_list) / 2, \"Max Throughput\", color=\"black\", rotation=90, \n",
    "         verticalalignment=\"center\", horizontalalignment=\"right\", fontsize=14)\n",
    "\n",
    "plt.title(f\"GPU-accel [0,M] with {model}\", size=20)\n",
    "plt.tight_layout()\n",
    "for save_format in save_formats:\n",
    "    plt.savefig(f'./{save_format}/AccelGain_BlockLoss-GLayer-{device}-{type}-{model}-{date_label}.{save_format}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45f5ff67",
   "metadata": {},
   "source": [
    "##### 3. net gain - glayers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1905f1ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_accelerated_layer_list를 기준으로 정렬\n",
    "sorted_data = sorted(zip(num_accelerated_layer_list, acceleration_gain_list, block_time_list))\n",
    "\n",
    "# 정렬된 데이터 분리\n",
    "sorted_num_accelerated_layer_list, sorted_acceleration_gain_list, sorted_block_time_list = zip(*sorted_data)\n",
    "net_gain_list = [a - b for a, b in zip(sorted_acceleration_gain_list, sorted_block_time_list)]\n",
    "\n",
    "# 2개의 y축을 가지는 그래프 생성\n",
    "fig, ax1 = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "# 첫 번째 y축 (total_execution_time_list)\n",
    "color = \"tab:orange\"\n",
    "ax1.set_xlabel(\"Acceleration Gain\", size=20)\n",
    "ax1.set_ylabel(\"Net Gain (Acceleration Gain - Block Loss)\", size=20)\n",
    "ax1.plot(sorted_num_accelerated_layer_list, net_gain_list, color=color, linestyle=\"-\", label=\"Throughput\")\n",
    "ax1.tick_params(axis=\"y\", labelsize=12)\n",
    "\n",
    "ax1.grid(True, which=\"both\", linestyle=\"--\", linewidth=0.5, alpha=0.7)\n",
    "\n",
    "ax1.axvline(x=corresponding_delay_num_of_accelerated_layers, color=\"gold\", linewidth=3, linestyle=\"--\")\n",
    "ax1.text(corresponding_delay_num_of_accelerated_layers, np.mean(net_gain_list), \"Max Throughput\", color=\"black\", rotation=90, \n",
    "         verticalalignment=\"center\", horizontalalignment=\"right\", fontsize=14)\n",
    "\n",
    "\n",
    "plt.title(f\"GPU-accel [0,M] with {model}\", size=20)\n",
    "plt.tight_layout()\n",
    "for save_format in save_formats:\n",
    "    plt.savefig(f'./{save_format}/NetGain-GLayer-{device}-{type}-{model}-{date_label}.{save_format}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "343c80f3",
   "metadata": {},
   "source": [
    "##### 4. throughput - delay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "413a0190",
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_accelerated_layer_list를 기준으로 정렬\n",
    "sorted_data = sorted(zip(num_accelerated_layer_list, max_execution_time_list, throughput_list))\n",
    "\n",
    "# 정렬된 데이터 분리\n",
    "sorted_num_accelerated_layer_list, sorted_max_execution_time_list, sorted_throughput_list = zip(*sorted_data)\n",
    "\n",
    "# MAX throughput과 그때의 delay 계산 및 출력\n",
    "max_throughput = max(sorted_throughput_list)\n",
    "max_throughput_index = sorted_throughput_list.index(max_throughput)\n",
    "corresponding_delay = sorted_max_execution_time_list[max_throughput_index]\n",
    "corresponding_delay_num_of_accelerated_layers = sorted_num_accelerated_layer_list[max_throughput_index]\n",
    "\n",
    "print(\"MAX Throughput Index:\", max_throughput_index)\n",
    "print(\"MAX Throughput:\", max_throughput)\n",
    "print(\"Corresponding Number of Accelerated Layers:\", corresponding_delay_num_of_accelerated_layers)\n",
    "print(\"Corresponding Delay:\", corresponding_delay)\n",
    "\n",
    "\n",
    "# 2개의 y축을 가지는 그래프 생성\n",
    "fig, ax1 = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "color = \"tab:red\"\n",
    "ax1.set_ylabel(\"Throughput (task/ms)\", size=20)\n",
    "ax1.set_xlabel(\"Delay (ms)\", size=20)\n",
    "ax1.plot(sorted_max_execution_time_list, sorted_throughput_list, color=color, linestyle=\"-\", label=\"Throughput\")\n",
    "ax1.tick_params(axis=\"y\", labelsize=12)\n",
    "\n",
    "ax1.grid(True, which=\"both\", linestyle=\"--\", linewidth=0.5, alpha=0.7)\n",
    "\n",
    "\n",
    "plt.title(f\"GPU-accel [0,M] with {model}\", size=20)\n",
    "plt.tight_layout()\n",
    "for save_format in save_formats:\n",
    "    plt.savefig(f'./{save_format}/Throughput-Delay-{device}-{type}-{model}-{date_label}.{save_format}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec017ec4",
   "metadata": {},
   "source": [
    "##### 5. block loss - acceleration gain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7abecc59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_accelerated_layer_list를 기준으로 정렬\n",
    "sorted_data = sorted(zip(num_accelerated_layer_list, acceleration_gain_list, block_time_list))\n",
    "\n",
    "# 정렬된 데이터 분리\n",
    "sorted_num_accelerated_layer_list, sorted_acceleration_gain_list, sorted_block_time_list = zip(*sorted_data)\n",
    "\n",
    "# 2개의 y축을 가지는 그래프 생성\n",
    "fig, ax1 = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "# 첫 번째 y축 (total_execution_time_list)\n",
    "color = \"tab:blue\"\n",
    "ax1.set_ylabel(\"Block loss\", size=20)\n",
    "ax1.set_xlabel(\"Acceleration Gain\", size=20)\n",
    "ax1.plot(sorted_acceleration_gain_list, sorted_block_time_list, color=color, linestyle=\"-\", label=\"Throughput\")\n",
    "ax1.tick_params(axis=\"y\", labelsize=12)\n",
    "ax1.grid(True, which=\"both\", linestyle=\"--\", linewidth=0.5, alpha=0.7)\n",
    "\n",
    "plt.title(f\"GPU-accel [0,M] with {model}\", size=20)\n",
    "plt.tight_layout()\n",
    "for save_format in save_formats:\n",
    "    plt.savefig(f'./{save_format}/BlockLos-AccelGain-{device}-{type}-{model}-{date_label}.{save_format}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "952ac523",
   "metadata": {},
   "source": [
    "### 기본그래프\n",
    "### 이거 무슨 그래프인지 잘 모르겠음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d95af26f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the plot\n",
    "fig, ax1 = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "color = \"black\"\n",
    "ax1.scatter(total_execution_time_list, throughput_list, color=color, s= 2)\n",
    "\n",
    "ax1.set_xlabel('1,000 Data - Total execution time (ms)', size=20)\n",
    "ax1.set_ylabel(\"Throughput (task/ms)\", size=20)\n",
    "\n",
    "ax1.tick_params(axis='both', labelsize=12)\n",
    "plt.title(f\"Throughput vs Total Execution Time with {model}\", fontsize=20)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Set up the plot\n",
    "fig, ax1 = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "color = \"black\"\n",
    "ax1.scatter(avg_execution_time_list, throughput_list, color=color, s= 2)\n",
    "\n",
    "ax1.set_xlabel('Delay (ms)', size=20)\n",
    "ax1.set_ylabel(\"Throughput (task/ms)\", size=20)\n",
    "\n",
    "ax1.tick_params(axis='both', labelsize=12)\n",
    "plt.title(f\"Impact of Delay on Throughput with {model}\", fontsize=20)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f7f5070f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [0,M] & [start, M] 구성 찾기\n",
    "all_results = []\n",
    "\n",
    "# 모든 start 값에 대한 배열 생성\n",
    "for start in range(0, 1):\n",
    "    result = []\n",
    "    for i in range(start, layer_num-2):\n",
    "        row = [0] + [0] * start + [1] * (i - start + 1) + [0] * (layer_num -2 - (i + 1)) + [0]\n",
    "        result.append(row)\n",
    "    all_results.append(result)\n",
    "\n",
    "# 각 배열이 acceleration_type에서 몇 번째 인덱스에 있는지 저장\n",
    "all_results_indexes = []\n",
    "\n",
    "for result in all_results:\n",
    "    result_indexes = []\n",
    "    for row in result:\n",
    "        # row를 튜플로 변환하여 acceleration_type에서의 인덱스 확인\n",
    "        index = acceleration_type.index(row)\n",
    "        result_indexes.append(index)\n",
    "    all_results_indexes.append(result_indexes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c37e319e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the plot\n",
    "fig, ax1 = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "color = \"black\"\n",
    "ax1.scatter(max_execution_time_list, throughput_list, color=color, zorder=-start, s=2)\n",
    "\n",
    "# all_results_indexes에 있는 점들을 파란색으로 추가\n",
    "for indexes in all_results_indexes:\n",
    "    for idx in indexes:\n",
    "        ax1.scatter(max_execution_time_list[idx], throughput_list[idx], color='blue', s=10, zorder=1)\n",
    "\n",
    "# start = 0인 애들은 빨간색으로 한 번 더 찍기\n",
    "for idx in all_results_indexes[0]:  # all_results_indexes[0]이 start=0에 해당하는 인덱스들임\n",
    "    print(idx)\n",
    "    ax1.scatter(max_execution_time_list[idx], throughput_list[idx], color='red', s=10, zorder=2)\n",
    "\n",
    "# Delay에는 Block time이 포함됨\n",
    "ax1.set_xlabel('Delay (ms)', size=20)\n",
    "ax1.set_ylabel(\"Throughput (task/ms)\", size=20)\n",
    "ax1.tick_params(axis='both', labelsize=12)\n",
    "plt.title(f\"Impact of Delay on Throughput with {model}\", fontsize=20)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "434ae67e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# throughput_list에서 최대값, 해당 인덱스, 그리고 max_execution_time_list 값을 찾기\n",
    "max_throughput = max(throughput_list)\n",
    "max_index = throughput_list.index(max_throughput)\n",
    "corresponding_execution_time = max_execution_time_list[max_index]\n",
    "corresponding_acceleration_type = acceleration_type[max_index]\n",
    "\n",
    "# 결과 출력\n",
    "print(f\"최대 Throughput 값: {max_throughput}\")\n",
    "print(f\"최대 Throughput이 발생한 인덱스: {max_index}\")\n",
    "print(f\"해당 인덱스의 avg_execution_time: {corresponding_execution_time}\")\n",
    "print(f\"해당 인덱스의 acceleration_type: {corresponding_acceleration_type}\")\n",
    "\n",
    "print(len(corresponding_acceleration_type))\n",
    "print(corresponding_acceleration_type)\n",
    "\n",
    "# 합 계산\n",
    "total_inference_time = sum(\n",
    "    cpu_inference_list[i] if corresponding_acceleration_type[i] == 0 else gpu_inference_list[i]\n",
    "    for i in range(len(corresponding_acceleration_type))\n",
    ")\n",
    "\n",
    "# 결과 출력\n",
    "total_cpu_time = sum(cpu_inference_list)\n",
    "acceleration_gain = total_cpu_time - total_inference_time\n",
    "print(f\"\\n전체 CPU 실행 inference 시간: {total_cpu_time}\")\n",
    "print(f\"최종 합산된 inference 시간: {total_inference_time}\")\n",
    "print(f\"가속 이득: {acceleration_gain}\")\n",
    "block_time = max_execution_time-total_inference_time\n",
    "print(f\"블락 손실: {block_time}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ccd4a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the plot\n",
    "fig, ax1 = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "color = \"black\"\n",
    "ax1.scatter(acceleration_gain_list, block_time_list, color=color, zorder=-start, s=2)\n",
    "\n",
    "# all_results_indexes에 있는 점들을 파란색으로 추가\n",
    "for indexes in all_results_indexes:\n",
    "    for idx in indexes:\n",
    "        ax1.scatter(acceleration_gain_list[idx], block_time_list[idx], color='blue', s=10, zorder=1)\n",
    "\n",
    "# start = 0인 애들은 빨간색으로 한 번 더 찍기\n",
    "for idx in all_results_indexes[0]:  # all_results_indexes[0]이 start=0에 해당하는 인덱스들임\n",
    "    ax1.scatter(acceleration_gain_list[idx], block_time_list[idx], color='red', s=10, zorder=2)\n",
    "\n",
    "\n",
    "ax1.set_xlabel('Acceleraion Gain (ms)', size=20)\n",
    "ax1.set_ylabel(\"Block Loss (ms)\", size=20)\n",
    "ax1.tick_params(axis='both', labelsize=12)\n",
    "plt.title(f\"Block Loss vs Acceleraion Gain with {model}\", fontsize=20)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(len(throughput_list))\n",
    "\n",
    "# throughput_list에서 최대값, 해당 인덱스, 그리고 max_execution_time_list 값을 찾기\n",
    "max_throughput = max(acceleration_gain_list)\n",
    "max_index = acceleration_gain_list.index(max_throughput)\n",
    "corresponding_execution_time = block_time_list[max_index]\n",
    "corresponding_acceleration_type = acceleration_type[max_index]\n",
    "\n",
    "# 결과 출력\n",
    "print(f\"최대 acceleration_gain_list 값: {max_throughput}\")\n",
    "print(f\"최대 acceleration_gain_list 발생한 인덱스: {max_index}\")\n",
    "print(f\"해당 인덱스의 block_time_list: {corresponding_execution_time}\")\n",
    "print(f\"해당 인덱스의 acceleration_type: {corresponding_acceleration_type}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e36ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# acceleration_gain - block_time 계산\n",
    "loss_difference = [acc - block for acc, block in zip(acceleration_gain_list, block_time_list)]\n",
    "\n",
    "# Set up the plot\n",
    "fig, ax1 = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "# 흑색으로 전체 데이터 점 표현\n",
    "color = \"black\"\n",
    "ax1.scatter(acceleration_gain_list, loss_difference, color=color, zorder=-start, s=2)\n",
    "\n",
    "# all_results_indexes에 있는 점들을 파란색으로 추가\n",
    "for indexes in all_results_indexes:\n",
    "    for idx in indexes:\n",
    "        ax1.scatter(acceleration_gain_list[idx], loss_difference[idx], color='blue', s=10, zorder=1)\n",
    "\n",
    "# start = 0인 애들은 빨간색으로 한 번 더 찍기\n",
    "for idx in all_results_indexes[0]:  # all_results_indexes[0]이 start=0에 해당하는 인덱스들임\n",
    "    ax1.scatter(acceleration_gain_list[idx], loss_difference[idx], color='red', s=10, zorder=2)\n",
    "\n",
    "# 축 라벨 및 설정\n",
    "ax1.set_xlabel('Acceleration Gain (ms)', size=20)\n",
    "ax1.set_ylabel('Net Gain (Acceleration - Block Loss) (ms)', size=20)\n",
    "ax1.tick_params(axis='both', labelsize=12)\n",
    "plt.title(f\"Net Gain vs Acceleraion Gain with {model}\", fontsize=20)\n",
    "\n",
    "# 그래프 표시\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 최대 acceleration_gain - block_time 값을 찾기\n",
    "max_difference = max(loss_difference)\n",
    "max_index = loss_difference.index(max_difference)\n",
    "corresponding_acceleration_gain = acceleration_gain_list[max_index]\n",
    "corresponding_block_time = block_time_list[max_index]\n",
    "\n",
    "# 결과 출력\n",
    "print(f\"최대 acceleration_gain - block_time 값: {max_difference}\")\n",
    "print(f\"최대값 발생한 인덱스: {max_index}\")\n",
    "print(f\"해당 인덱스의 acceleration_gain: {corresponding_acceleration_gain}\")\n",
    "print(f\"해당 인덱스의 block_time: {corresponding_block_time}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d3f9625",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Set up the plot\n",
    "fig, ax1 = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "# Normalize throughput_list for color mapping\n",
    "norm_throughput = (throughput_list - np.min(throughput_list)) / (np.max(throughput_list) - np.min(throughput_list))\n",
    "\n",
    "# Scatter plot with z-axis represented by colors\n",
    "scatter = ax1.scatter(\n",
    "    acceleration_gain_list, \n",
    "    block_time_list, \n",
    "    c=throughput_list, # norm_throughput\n",
    "    cmap='viridis',  # Choose a color map\n",
    "    s=10,  # Adjust size of points\n",
    "    zorder=1\n",
    ")\n",
    "\n",
    "# Colorbar for throughput values\n",
    "cbar = fig.colorbar(scatter, ax=ax1)\n",
    "cbar.set_label('Throughput (task/ms)', size=20)\n",
    "cbar.ax.tick_params(labelsize=12)\n",
    "\n",
    "# start=0 points highlighted in red\n",
    "for idx in all_results_indexes[0]:  # Points corresponding to start=0\n",
    "    ax1.scatter(acceleration_gain_list[idx], block_time_list[idx], color='red', s=30, zorder=-100)\n",
    "\n",
    "# Axis labels\n",
    "ax1.set_xlabel('Acceleration Gain (ms)', size=20)\n",
    "ax1.set_ylabel('Block Time (ms)', size=20)\n",
    "ax1.tick_params(axis='both', labelsize=12)\n",
    "plt.title(f\"{model}\\nThroughput Analysis: Acceleration Gain vs Block Time\", fontsize = 20)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Maximum throughput analysis\n",
    "max_throughput = max(throughput_list)\n",
    "max_index = throughput_list.index(max_throughput)\n",
    "corresponding_acceleration_gain = acceleration_gain_list[max_index]\n",
    "corresponding_block_time = block_time_list[max_index]\n",
    "\n",
    "# Results output\n",
    "print(f\"최대 throughput 값: {max_throughput}\")\n",
    "print(f\"최대 throughput 발생한 인덱스: {max_index}\")\n",
    "print(f\"해당 인덱스의 acceleration_gain: {corresponding_acceleration_gain}\")\n",
    "print(f\"해당 인덱스의 block_time: {corresponding_block_time}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac5a8189",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "# Bubble Chart\n",
    "scatter = ax.scatter(\n",
    "    acceleration_gain_list, \n",
    "    block_time_list, \n",
    "    s=np.array(throughput_list) * 10,  # 크기를 throughput_list로 설정\n",
    "    c=throughput_list, \n",
    "    cmap='viridis', \n",
    "    alpha=0.7\n",
    ")\n",
    "\n",
    "# Colorbar\n",
    "cbar = fig.colorbar(scatter, ax=ax)\n",
    "cbar.set_label('Throughput (task/ms)', size=20)\n",
    "plt.title(f\"{model}\\nThroughput Analysis: Acceleration Gain vs Block Time\", fontsize = 20)\n",
    "# Labels\n",
    "ax.set_xlabel('Acceleration Gain (ms)', size=20)\n",
    "ax.set_ylabel('Block Time (ms)', size=20)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "560ac3ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "# Hexbin Plot\n",
    "hb = ax.hexbin(\n",
    "    acceleration_gain_list, \n",
    "    block_time_list, \n",
    "    C=throughput_list, \n",
    "    gridsize=30, \n",
    "    cmap='viridis'\n",
    ")\n",
    "\n",
    "# Colorbar\n",
    "cbar = fig.colorbar(hb, ax=ax)\n",
    "cbar.set_label('Throughput (task/ms)', size=20)\n",
    "plt.title(f\"{model}\\nThroughput Analysis: Acceleration Gain vs Block Time\", fontsize = 20)\n",
    "# Labels\n",
    "ax.set_xlabel('Acceleration Gain (ms)', size=20)\n",
    "ax.set_ylabel('Block Time (ms)', size=20)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f12dfec",
   "metadata": {},
   "source": [
    "### 히스토그램"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b8a1bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 평균값 계산\n",
    "acceleration_mean = np.mean(acceleration_gain_list)\n",
    "block_mean = np.mean(block_time_list)\n",
    "loss_mean = np.mean(loss_difference)\n",
    "\n",
    "# 서브플롯 생성\n",
    "fig, axes = plt.subplots(1, 3, figsize=(15, 5), constrained_layout=True)\n",
    "\n",
    "# 첫 번째 히스토그램 (연한 파랑)\n",
    "axes[0].hist(acceleration_gain_list, bins=10, edgecolor='black', color='lightblue')\n",
    "axes[0].axvline(x=acceleration_mean, color='red', linestyle='--', label=f'Mean: {acceleration_mean:.2f}', linewidth=4)\n",
    "axes[0].set_title(\"Acceleration Gain Distribution\", fontsize=20)\n",
    "axes[0].set_xlabel(\"Acceleration Gain (ms)\", fontsize=20)\n",
    "axes[0].set_ylabel(\"Frequency\", fontsize=20)\n",
    "axes[0].legend()\n",
    "\n",
    "# 두 번째 히스토그램 (연한 주황)\n",
    "axes[1].hist(block_time_list, bins=10, edgecolor='black', color='peachpuff')\n",
    "axes[1].axvline(x=block_mean, color='red', linestyle='--', label=f'Mean: {block_mean:.2f}', linewidth=4)\n",
    "axes[1].set_title(\"Block Loss Distribution\", fontsize=20)\n",
    "axes[1].set_xlabel(\"Block Loss (ms)\", fontsize=20)\n",
    "axes[1].set_ylabel(\"Frequency\", fontsize=20)\n",
    "axes[1].legend()\n",
    "\n",
    "# 세 번째 히스토그램 (연한 초록)\n",
    "axes[2].hist(loss_difference, bins=10, edgecolor='black', color='lightgreen')\n",
    "axes[2].axvline(x=loss_mean, color='red', linestyle='--', label=f'Mean: {loss_mean:.2f}', linewidth=4)\n",
    "axes[2].set_title(\"Net Gain (Acceleration - Block Loss) Distribution\", fontsize=20)\n",
    "axes[2].set_xlabel(\"Net Gain (Acceleration - Block Loss)\", fontsize=20)\n",
    "axes[2].set_ylabel(\"Frequency\", fontsize=20)\n",
    "axes[2].legend()\n",
    "\n",
    "# 그래프 출력\n",
    "fig.suptitle(f\"Distribution Analysis with {model}\", fontsize=24, y=1.1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af801254",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
